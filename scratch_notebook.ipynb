{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996ffcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/geopandas-101-plot-any-data-with-a-latitude-and-longitude-on-a-map-98e01944b972"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b75585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "\n",
    "# Visualizing\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "#Visual format\n",
    "pd.options.display.float_format = '{:20,.4f}'.format\n",
    "\n",
    "#my libraries\n",
    "from wrangle import get_zillow_data, wrangle_zillow, remove_outliers, train_validate_test_split, get_hist, get_box\n",
    "from explore import plot_against_target, inertia\n",
    "import evaluate\n",
    "import model\n",
    "import env\n",
    "\n",
    "#library imports\n",
    "from datetime import date\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression, LassoLars\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, RFE\n",
    "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# Statistical Tests\n",
    "import scipy.stats as stats\n",
    "\n",
    "#alpha\n",
    "alpha = .05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8643318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_zillow_data()\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf805b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wrangle_zillow(df)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e63fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    df['age_bin'] = pd.cut(df.age, \n",
    "                           bins = [0, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140],\n",
    "                           labels = [0, .066, .133, .20, .266, .333, .40, .466, .533, \n",
    "                                     .60, .666, .733, .8, .866, .933])\n",
    "\n",
    "    # square feet bin\n",
    "    df['sqft_bin'] = pd.cut(df.sqft, \n",
    "                            bins = [0, 800, 1000, 1250, 1500, 2000, 2500, 3000, 4000, 7000, 12000],\n",
    "                            labels = [0, .1, .2, .3, .4, .5, .6, .7, .8, .9])\n",
    "\n",
    "    df['ppsqft_bin'] = pd.cut(df.price_per_sqft, \n",
    "                                             bins = [0, 25, 50, 75, 100, 150, 200, 300, 500, 1000, 1500],\n",
    "                                             labels = [0, .1, .2, .3, .4, .5, .6, .7, .8, .9])\n",
    "\n",
    "    # update datatypes of binned values to be float\n",
    "    df = df.astype({'age_bin': 'float64', 'sqft_bin': 'float64', 'ppsqft_bin': 'float64'})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b0c37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_features(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d765d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db7a5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa4f7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age_bin.fillna(0.3749, inplace = True)\n",
    "df.sqft_bin.fillna(0.3551, inplace = True)\n",
    "df.ppsqft_bin.fillna(0.5427, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da218da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95562be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a0232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df, target_var):\n",
    "    '''\n",
    "    This function takes in the dataframe and target variable name as arguments and then\n",
    "    splits the dataframe into train (56%), validate (24%), & test (20%)\n",
    "    It will return a list containing the following dataframes: train (for exploration), \n",
    "    X_train, X_validate, X_test, y_train, y_validate, y_test\n",
    "    '''\n",
    "    # split df into train_validate (80%) and test (20%)\n",
    "    train_validate, test = train_test_split(df, test_size=.20, random_state=13)\n",
    "    # split train_validate into train(70% of 80% = 56%) and validate (30% of 80% = 24%)\n",
    "    train, validate = train_test_split(train_validate, test_size=.3, random_state=13)\n",
    "\n",
    "    # create X_train by dropping the target variable \n",
    "    X_train = train.drop(columns=[target_var])\n",
    "    # create y_train by keeping only the target variable.\n",
    "    y_train = train[[target_var]]\n",
    "\n",
    "    # create X_validate by dropping the target variable \n",
    "    X_validate = validate.drop(columns=[target_var])\n",
    "    # create y_validate by keeping only the target variable.\n",
    "    y_validate = validate[[target_var]]\n",
    "\n",
    "    # create X_test by dropping the target variable \n",
    "    X_test = test.drop(columns=[target_var])\n",
    "    # create y_test by keeping only the target variable.\n",
    "    y_test = test[[target_var]]\n",
    "\n",
    "    partitions = [train, X_train, X_validate, X_test, y_train, y_validate, y_test]\n",
    "    return partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31209c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions = split(df, target_var='logerror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e11895",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = partitions[0]\n",
    "train['logerror_bins'] = pd.cut(train.logerror, [-5, -.2, -.05, .05, .2, 4])\n",
    "partitions[0] = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd20b7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.logerror_bins.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6479b56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data = train, hue = 'logerror_bins', \n",
    "             x_vars = ['logerror', 'age_bin', 'sqft_bin', 'ppsqft_bin'],\n",
    "             y_vars = ['logerror', 'age', 'sqft', 'price_per_sqft'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489a690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCALE\n",
    "\n",
    "# the variables that still need scaling\n",
    "scaled_vars = ['latitude', 'longitude', 'lot_size', 'tax_value', 'age', 'sqft']\n",
    "\n",
    "# create new column names for the scaled variables by adding 'scaled_' to the beginning of each variable name \n",
    "scaled_column_names = ['scaled_' + i for i in scaled_vars]\n",
    "\n",
    "# select the X partitions: [X_train, X_validate, X_test]\n",
    "X = partitions[1:4]\n",
    "\n",
    "# fit the minmaxscaler to X_train\n",
    "X_train = X[0]\n",
    "scaler = MinMaxScaler(copy=True).fit(X_train[scaled_vars])\n",
    "\n",
    "\n",
    "def scale_and_concat(df):\n",
    "    scaled_array = scaler.transform(df[scaled_vars])\n",
    "    scaled_df = pd.DataFrame(scaled_array, columns=scaled_column_names, index=df.index.values)\n",
    "    return pd.concat((df, scaled_df), axis=1)\n",
    "\n",
    "for i in range(len(X)):\n",
    "    X[i] = scale_and_concat(X[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467eae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall: X[0] is X_train, X[1] is X_validate and X[2] is X_test\n",
    "X[0].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5af0ef",
   "metadata": {},
   "source": [
    "# Cluster 1: Age, Long and Lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2027e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of variables I will cluster on. \n",
    "cluster_vars = ['scaled_latitude', 'scaled_longitude', 'age_bin']\n",
    "cluster_name = 'area_cluster'\n",
    "k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cb2550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clusters(X_train, k, cluster_vars):\n",
    "    # create kmean object\n",
    "    kmeans = KMeans(n_clusters=k, random_state = 13)\n",
    "\n",
    "    # fit to train and assign cluster ids to observations\n",
    "    kmeans.fit(X_train[cluster_vars])\n",
    "\n",
    "    return kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f618e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = create_clusters(X[0], k, cluster_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ec0912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroids(kmeans, cluster_vars, cluster_name):\n",
    "    # get the centroids for each distinct cluster...\n",
    "\n",
    "    centroid_col_names = ['centroid_' + i for i in cluster_vars]\n",
    "\n",
    "    centroid_df = pd.DataFrame(kmeans.cluster_centers_, \n",
    "                               columns=centroid_col_names).reset_index().rename(columns={'index': cluster_name})\n",
    "\n",
    "    return centroid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65225d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_df = get_centroids(kmeans, cluster_vars, cluster_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca948db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label cluster for each observation in X_train (X[0] in our X list of dataframes), \n",
    "# X_validate (X[1]), & X_test (X[2])\n",
    "\n",
    "def assign_clusters(kmeans, cluster_vars, cluster_name, centroid_df):\n",
    "    for i in range(len(X)):\n",
    "        clusters = pd.DataFrame(kmeans.predict(X[i][cluster_vars]), \n",
    "                            columns=[cluster_name], index=X[i].index)\n",
    "\n",
    "        clusters_centroids = clusters.merge(centroid_df, on=cluster_name, copy=False).set_index(clusters.index.values)\n",
    "\n",
    "        X[i] = pd.concat([X[i], clusters_centroids], axis=1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf48ee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = assign_clusters(kmeans, cluster_vars, cluster_name, centroid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48fa959",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X[0].groupby(['area_cluster', 'centroid_scaled_latitude', 'centroid_scaled_longitude', \n",
    "                           'centroid_age_bin'])['area_cluster'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e55d52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818fe71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "# plt.scatter(y=X_train.latitude, x=X_train.longitude, c=X_train.area_cluster, alpha=.4)\n",
    "plt.scatter(y=X[0].age, x=X[0].longitude, c=X[0].area_cluster, alpha=.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207e4274",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = partitions[-3]\n",
    "\n",
    "plt.scatter(y=y_train.logerror, x=X[0].age, c=X[0].area_cluster, alpha=.7)\n",
    "plt.ylim(-1,1)\n",
    "plt.xlabel('Age of Property')\n",
    "plt.ylabel('Log Error of Zestimate')\n",
    "plt.title(\"Do clusters reveal differences in age and error?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8e3bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y=y_train.logerror, x=X[0].area_cluster)\n",
    "plt.ylim(-1, 1)\n",
    "# sns.swarmplot(X_train.age_bin, y_train.logerror, hue=X_train.area_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627f187a",
   "metadata": {},
   "source": [
    "# Cluster 2: Age, Sqft and Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ec4995",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd3fde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_vars = ['bathrooms', 'bedrooms', 'ppsqft_bin']\n",
    "cluster_name = 'aged_cluster'\n",
    "k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5623a82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = create_clusters(X[0], k, cluster_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e97044",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_df = get_centroids(kmeans, cluster_vars, cluster_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91873c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = assign_clusters(kmeans, cluster_vars, cluster_name, centroid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cafb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X[0].groupby(['aged_cluster', 'centroid_bathrooms', 'centroid_bedrooms', \n",
    "                           'centroid_ppsqft_bin'])['aged_cluster'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f3a46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "# plt.scatter(y=X_train.latitude, x=X_train.longitude, c=X_train.area_cluster, alpha=.4)\n",
    "plt.scatter(y=X[0].price_per_sqft, x=X[0].bedrooms, c=X[0].aged_cluster, alpha=.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fc08af",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = partitions[-3]\n",
    "\n",
    "plt.scatter(y=y_train.logerror, x=X[0].price_per_sqft, c=X[0].aged_cluster, alpha=.7)\n",
    "plt.ylim(-1,1)\n",
    "plt.xlabel('Age of Property')\n",
    "plt.ylabel('Log Error of Zestimate')\n",
    "plt.title(\"Do clusters reveal differences in age and error?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d0a9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y=y_train.logerror, x=X[0].aged_cluster)\n",
    "plt.ylim(-1, 1)\n",
    "# sns.swarmplot(X_train.age_bin, y_train.logerror, hue=X_train.area_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edf01df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "# plt.scatter(y=X_train.latitude, x=X_train.longitude, c=X_train.area_cluster, alpha=.4)\n",
    "plt.scatter(y=y_train.logerror, x=X[0].sqft, c=X[0].aged_cluster, alpha=.7)\n",
    "plt.yscale('symlog')\n",
    "plt.xlabel('Finished Square Feet')\n",
    "plt.ylabel('Log Error of Zestimate')\n",
    "plt.title('Is there distinction between clusters when visualizing size of the home by the error in zestimate?')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43913d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_df = X[0][['bathrooms', 'bedrooms', 'sqft', 'aged_cluster']]\n",
    "\n",
    "sns.pairplot(data=plt_df, hue='aged_cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef244bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='bedrooms', y='sqft', \n",
    "                data=X[0], hue='aged_cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9725928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update datatypes of binned values to be float\n",
    "X_train = X[0].astype({'aged_cluster': 'category', 'area_cluster': 'category'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a38453",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df = pd.get_dummies(X[0][['aged_cluster','area_cluster']], dummy_na=False, drop_first=[True, True])\n",
    "\n",
    "# append dummy df cols to the original df. \n",
    "X_train = pd.concat([X_train, dummy_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228a8ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568df82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f481f6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [['aged_cluster', 'area_cluster']]#features\n",
    "y_train = X[0].logerror\n",
    "X_validate = [['aged_cluster', 'area_cluster']]#features\n",
    "y_validate = X[1].logerror\n",
    "X_test = [['aged_cluster', 'area_cluster']]#features\n",
    "y_test = X[2].logerror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718a3431",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate.rfe(X_train,y_train,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12257927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8712ae62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191b23bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caf4bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cf12c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f49aec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3004b667",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "# plt.scatter(y=X_train.latitude, x=X_train.longitude, c=X_train.area_cluster, alpha=.4)\n",
    "plt.scatter(y=y_train.logerror, x=X_train.sqft, c=X_train.size_cluster, alpha=.7)\n",
    "plt.yscale('symlog')\n",
    "plt.xlabel('Finished Square Feet')\n",
    "plt.ylabel('Log Error of Zestimate')\n",
    "plt.title('Is there distinction between clusters when visualizing size of the home by the error in zestimate?')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc00fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1755952b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c84c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a437cca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train, validate, test = train_validate_test_split(df)\n",
    "print(\"train observations: \", train.shape)\n",
    "print(\"validate observations: \", validate.shape)\n",
    "print(\"test observations: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2814ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bb5a9f",
   "metadata": {},
   "source": [
    "# Explore\n",
    "- We are not going to explore the scaled data at this time, but it is important that the data is scaled before moving into clustering.\n",
    "\n",
    "- Target Variable: 'log_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38ed41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What are the distributions of each variable (train)\n",
    "for col in train.columns:\n",
    "    plt.figure(figsize=(4,2))\n",
    "    plt.hist(train[col])\n",
    "    plt.title(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796890cd",
   "metadata": {},
   "source": [
    "##### Takeawyas\n",
    "- right skewed tax_value, square_feet, and tax_rate\n",
    "- bit of a left skew on age\n",
    "- log_error normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26252660",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['bathrooms', 'bedrooms', 'sqft', 'latitude', 'longitude', 'lot_size', 'tax_value', 'age', \n",
    "            'tax_rate', 'price_per_sqft', 'county_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b4109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_against_target(df = train, target = 'logerror', var_list = variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410640c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['age', 'latitude', 'longitude', 'logerror']\n",
    "\n",
    "sns.pairplot(data = train[cols], corner=True)\n",
    "\n",
    "plt.suptitle('Amount of error is to see with Logerror', fontsize = 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0963640",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(x=\"county\", y=\"logerror\", data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8077aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(train.county, train.logerror)\n",
    "plt.title('Potential difference in logerror across counties')\n",
    "plt.ylim(-.16, .16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c80526",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cols = ['age', 'bathrooms', 'bedrooms', 'sqft', 'price_per_sqft', 'lot_size', 'tax_value', 'logerror']\n",
    "\n",
    "sns.pairplot(data = train[cols], corner=True)\n",
    "\n",
    "plt.suptitle('Amount of error is to see with Logerror', fontsize = 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d072cc6",
   "metadata": {},
   "source": [
    "1. Higher Log errors with homes these features:\n",
    "    - Homes <60 yrs \n",
    "    - <= 4 bathrooms\n",
    "    - <= 5 bedrooms\n",
    "    - <= 2500sqft\n",
    "    - < 1,000 dollars per sqft\n",
    "    - ?? Lot size\n",
    "    - ?? Home value\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7bd19a",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e21fd5",
   "metadata": {},
   "source": [
    "## Scaled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68c60f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale\n",
    "# Start w/ empty copies to retain the original splits\n",
    "train_scaled = train.copy()\n",
    "validate_scaled = validate.copy()\n",
    "test_scaled = test.copy()\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "cols = train.drop(columns=[\"county\"]).columns.tolist()\n",
    "\n",
    "\n",
    "train_scaled[cols] = scaler.fit_transform(train[cols])\n",
    "validate_scaled[cols] = scaler.fit_transform(validate[cols])\n",
    "test_scaled[cols] = scaler.fit_transform(test[cols])\n",
    "\n",
    "# Add back in the gender column to the dataframes\n",
    "train_scaled[\"county\"] = train.county.copy()\n",
    "validate_scaled[\"county\"] = validate.county.copy()\n",
    "test_scaled[\"county\"] = test.county.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d46fce",
   "metadata": {},
   "source": [
    "## cluster 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73d471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_scaled[['latitude', 'longitude']]\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(X)\n",
    "train_scaled['cluster'] = kmeans.predict(X)\n",
    "centroids = pd.DataFrame(kmeans.cluster_centers_, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e7c540",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.groupby('cluster')['latitude', 'longitude'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f076591d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 9))\n",
    "\n",
    "for cluster, subset in train_scaled.groupby('cluster'):\n",
    "    plt.scatter(subset.longitude, subset.latitude, label='cluster ' + str(cluster), alpha=.6)\n",
    "\n",
    "centroids.plot.scatter(y='latitude', x='longitude', c='black', marker='x', s=1000, ax=plt.gca(), label='centroid')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('longitude')\n",
    "plt.ylabel('latitude')\n",
    "plt.title('Visualizing Cluster Centers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccffee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    pd.Series({k: KMeans(k).fit(X).inertia_ for k in range(2, 12)}).plot(marker='x')\n",
    "    plt.xticks(range(2, 12))\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('inertia')\n",
    "    plt.title('Change in inertia as k increases')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0814680a",
   "metadata": {},
   "source": [
    "## cluster 2 (logerror - age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc83734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_scaled[['logerror', 'age']]\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(X)\n",
    "train_scaled['cluster'] = kmeans.predict(X)\n",
    "centroids = pd.DataFrame(kmeans.cluster_centers_, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac1efc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.groupby('cluster')['logerror', 'age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37161734",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 9))\n",
    "\n",
    "for cluster, subset in train_scaled.groupby('cluster'):\n",
    "    plt.scatter(subset.age, subset.logerror, label='cluster ' + str(cluster), alpha=.6)\n",
    "\n",
    "centroids.plot.scatter(y='logerror', x='age', c='black', marker='x', s=1000, ax=plt.gca(), label='centroid')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('logerror')\n",
    "plt.ylabel('age')\n",
    "plt.title('Visualizing Cluster Centers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9469b95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    pd.Series({k: KMeans(k).fit(X).inertia_ for k in range(2, 12)}).plot(marker='x')\n",
    "    plt.xticks(range(2, 12))\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('inertia')\n",
    "    plt.title('Change in inertia as k increases')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a103646",
   "metadata": {},
   "source": [
    "## Cluster 3 (logerror - bathrooms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2538d499",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_scaled[['logerror', 'bathrooms']]\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(X)\n",
    "train_scaled['cluster'] = kmeans.predict(X)\n",
    "centroids = pd.DataFrame(kmeans.cluster_centers_, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05419319",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.groupby('cluster')['logerror', 'bathrooms'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c199ad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 9))\n",
    "\n",
    "for cluster, subset in train_scaled.groupby('cluster'):\n",
    "    plt.scatter(subset.bathrooms, subset.logerror, label='cluster ' + str(cluster), alpha=.6)\n",
    "\n",
    "centroids.plot.scatter(y='logerror', x='bathrooms', c='black', marker='x', s=1000, ax=plt.gca(), label='centroid')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('bathrooms')\n",
    "plt.ylabel('logerror')\n",
    "plt.title('Visualizing Cluster Centers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f629afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    pd.Series({k: KMeans(k).fit(X).inertia_ for k in range(2, 12)}).plot(marker='x')\n",
    "    plt.xticks(range(2, 12))\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('inertia')\n",
    "    plt.title('Change in inertia as k increases')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf2967b",
   "metadata": {},
   "source": [
    "## Cluster 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912c9760",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_scaled[['logerror', 'bedrooms']]\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(X)\n",
    "train_scaled['cluster'] = kmeans.predict(X)\n",
    "centroids = pd.DataFrame(kmeans.cluster_centers_, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee021dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.groupby('cluster')['logerror', 'bedrooms'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd0161e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 9))\n",
    "\n",
    "for cluster, subset in train_scaled.groupby('cluster'):\n",
    "    plt.scatter(subset.bedrooms, subset.logerror, label='cluster ' + str(cluster), alpha=.6)\n",
    "\n",
    "centroids.plot.scatter(y='logerror', x='bedrooms', c='black', marker='x', s=1000, ax=plt.gca(), label='centroid')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('bedrooms')\n",
    "plt.ylabel('logerror')\n",
    "plt.title('Visualizing Cluster Centers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f201ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    pd.Series({k: KMeans(k).fit(X).inertia_ for k in range(2, 12)}).plot(marker='x')\n",
    "    plt.xticks(range(2, 12))\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('inertia')\n",
    "    plt.title('Change in inertia as k increases')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9e93b9",
   "metadata": {},
   "source": [
    "## Cluster 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3ea18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_scaled[['logerror', 'sqft']]\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "kmeans.fit(X)\n",
    "train_scaled['cluster'] = kmeans.predict(X)\n",
    "centroids = pd.DataFrame(kmeans.cluster_centers_, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8efed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.groupby('cluster')['logerror', 'sqft'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed386563",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 9))\n",
    "\n",
    "for cluster, subset in train_scaled.groupby('cluster'):\n",
    "    plt.scatter(subset.sqft, subset.logerror, label='cluster ' + str(cluster), alpha=.6)\n",
    "\n",
    "centroids.plot.scatter(y='logerror', x='sqft', c='black', marker='x', s=1000, ax=plt.gca(), label='centroid')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('sqft')\n",
    "plt.ylabel('logerror')\n",
    "plt.title('Visualizing Cluster Centers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5945365",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    pd.Series({k: KMeans(k).fit(X).inertia_ for k in range(2, 12)}).plot(marker='x')\n",
    "    plt.xticks(range(2, 12))\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('inertia')\n",
    "    plt.title('Change in inertia as k increases')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed36e1e5",
   "metadata": {},
   "source": [
    "## Cluster 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23c004a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_scaled[['logerror', 'price_per_sqft']]\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(X)\n",
    "train_scaled['cluster'] = kmeans.predict(X)\n",
    "centroids = pd.DataFrame(kmeans.cluster_centers_, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db31a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.groupby('cluster')['logerror', 'price_per_sqft'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd3cba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 9))\n",
    "\n",
    "for cluster, subset in train_scaled.groupby('cluster'):\n",
    "    plt.scatter(subset.price_per_sqft, subset.logerror, label='cluster ' + str(cluster), alpha=.6)\n",
    "\n",
    "centroids.plot.scatter(y='logerror', x='price_per_sqft', c='black', marker='x', s=1000, ax=plt.gca(), label='centroid')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('price_per_sqft')\n",
    "plt.ylabel('loerror')\n",
    "plt.title('Visualizing Cluster Centers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2057b8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    pd.Series({k: KMeans(k).fit(X).inertia_ for k in range(2, 12)}).plot(marker='x')\n",
    "    plt.xticks(range(2, 12))\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('inertia')\n",
    "    plt.title('Change in inertia as k increases')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b946471",
   "metadata": {},
   "source": [
    "## Cluster 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf80413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_scaled[['logerror', 'lot_size']]\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(X)\n",
    "train_scaled['cluster'] = kmeans.predict(X)\n",
    "centroids = pd.DataFrame(kmeans.cluster_centers_, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5924825f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.groupby('cluster')['logerror', 'lot_size'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590d7f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 9))\n",
    "\n",
    "for cluster, subset in train_scaled.groupby('cluster'):\n",
    "    plt.scatter(subset.lot_size, subset.logerror, label='cluster ' + str(cluster), alpha=.6)\n",
    "\n",
    "centroids.plot.scatter(y='logerror', x='lot_size', c='black', marker='x', s=1000, ax=plt.gca(), label='centroid')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('lot_size')\n",
    "plt.ylabel('loerror')\n",
    "plt.title('Visualizing Cluster Centers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1234b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    pd.Series({k: KMeans(k).fit(X).inertia_ for k in range(2, 12)}).plot(marker='x')\n",
    "    plt.xticks(range(2, 12))\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('inertia')\n",
    "    plt.title('Change in inertia as k increases')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1bf339",
   "metadata": {},
   "source": [
    "## Cluster 9 (logerror - home value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec248f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_scaled[['logerror', 'tax_value']]\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(X)\n",
    "train_scaled['cluster'] = kmeans.predict(X)\n",
    "centroids = pd.DataFrame(kmeans.cluster_centers_, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6889a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.groupby('cluster')['logerror', 'tax_value'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430d5cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 9))\n",
    "\n",
    "for cluster, subset in train_scaled.groupby('cluster'):\n",
    "    plt.scatter(subset.tax_value, subset.logerror, label='cluster ' + str(cluster), alpha=.6)\n",
    "\n",
    "centroids.plot.scatter(y='logerror', x='tax_value', c='black', marker='x', s=1000, ax=plt.gca(), label='centroid')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('tax_value')\n",
    "plt.ylabel('loerror')\n",
    "plt.title('Visualizing Cluster Centers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03492e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context('seaborn-whitegrid'):\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    pd.Series({k: KMeans(k).fit(X).inertia_ for k in range(2, 12)}).plot(marker='x')\n",
    "    plt.xticks(range(2, 12))\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('inertia')\n",
    "    plt.title('Change in inertia as k increases')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba16f546",
   "metadata": {},
   "source": [
    "### Takeaways \n",
    "- Is a higher log error dependent on homes over 50 years old? (Cluster - 2)\n",
    "- Is a higher log error dependent on homes less 1000 sqft? (Cluster - 6)\n",
    "- Is a higher log error dependent on homes who's ppsqft is less 200? (Cluster - 7)\n",
    "- Is a higher log error dependent on homes with a smaller lot size? (Cluster - 8)\n",
    "- Is a higher log error dependent on less expensive homes? (Cluster - 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7285dacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create heatmap with scaled data\n",
    "plt.figure(figsize=(8,12))\n",
    "value_heatmap = sns.heatmap(train.corr()[['abs_logerror']].sort_values(by='abs_logerror', ascending=True), \n",
    "                            cmap='PuOr', vmin=-.5, vmax=.5, annot=True)\n",
    "value_heatmap.set_title('Feautures Correlating with Absolute Logerror')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89555b3",
   "metadata": {},
   "source": [
    "# Stats testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee55911",
   "metadata": {},
   "source": [
    "##### Is a higher log error dependent on homes over 50 years old? (Cluster - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a20d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Null = 'Is independent'\n",
    "Alternate = 'Is dependent'\n",
    "\n",
    "observed = pd.crosstab(train.logerror > 0, train.age > 50)\n",
    "chi2, p, degf, expected = stats.chi2_contingency(observed)\n",
    "\n",
    "print(f'chi^2 = {chi2:.4f}')\n",
    "print(f'p     = {p:.4f}')\n",
    "\n",
    "print('\\n')\n",
    "if p < alpha:\n",
    "    print(f'We reject the null and accept the alternate: {Alternate}')\n",
    "else:\n",
    "    print(f'We fail to reject the null and accept the null: {Null}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa193a9c",
   "metadata": {},
   "source": [
    "##### Is a higher log error dependent on homes less 1000 sqft? (Cluster - 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7340c3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Null = 'Is independent'\n",
    "Alternate = 'Is dependent'\n",
    "\n",
    "observed = pd.crosstab(train.logerror > 0, train.sqft > 1000)\n",
    "chi2, p, degf, expected = stats.chi2_contingency(observed)\n",
    "\n",
    "print(f'chi^2 = {chi2:.4f}')\n",
    "print(f'p     = {p:.4f}')\n",
    "\n",
    "print('\\n')\n",
    "if p < alpha:\n",
    "    print(f'We reject the null and accept the alternate: {Alternate}')\n",
    "else:\n",
    "    print(f'We fail to reject the null and accept the null: {Null}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445c5a16",
   "metadata": {},
   "source": [
    "##### Is a higher log error dependent on homes who's ppsqft is less 500? (Cluster - 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bae9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Null = 'Is independent'\n",
    "Alternate = 'Is dependent'\n",
    "\n",
    "observed = pd.crosstab(train.logerror > 0, train.price_per_sqft < 500)\n",
    "chi2, p, degf, expected = stats.chi2_contingency(observed)\n",
    "\n",
    "print(f'chi^2 = {chi2:.4f}')\n",
    "print(f'p     = {p:.4f}')\n",
    "\n",
    "print('\\n')\n",
    "if p < alpha:\n",
    "    print(f'We reject the null and accept the alternate: {Alternate}')\n",
    "else:\n",
    "    print(f'We fail to reject the null and accept the null: {Null}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c507e92",
   "metadata": {},
   "source": [
    "##### Is a higher log error dependent on homes with a smaller lot size? (Cluster - 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58da5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Null = 'Is independent'\n",
    "Alternate = 'Is dependent'\n",
    "\n",
    "observed = pd.crosstab(train.logerror > 0, train.lot_size < 236)\n",
    "chi2, p, degf, expected = stats.chi2_contingency(observed)\n",
    "\n",
    "print(f'chi^2 = {chi2:.4f}')\n",
    "print(f'p     = {p:.4f}')\n",
    "\n",
    "print('\\n')\n",
    "if p < alpha:\n",
    "    print(f'We reject the null and accept the alternate: {Alternate}')\n",
    "else:\n",
    "    print(f'We fail to reject the null and accept the null: {Null}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489fd61",
   "metadata": {},
   "source": [
    "##### Is a higher log error dependent on less expensive homes? (Cluster - 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627ff1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "Null = 'Is independent'\n",
    "Alternate = 'Is dependent'\n",
    "\n",
    "observed = pd.crosstab(train.logerror > 0, train.tax_value < 205000)\n",
    "chi2, p, degf, expected = stats.chi2_contingency(observed)\n",
    "\n",
    "print(f'chi^2 = {chi2:.4f}')\n",
    "print(f'p     = {p:.4f}')\n",
    "\n",
    "print('\\n')\n",
    "if p < alpha:\n",
    "    print(f'We reject the null and accept the alternate: {Alternate}')\n",
    "else:\n",
    "    print(f'We fail to reject the null and accept the null: {Null}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c51c6a",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f63c85",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7290ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_scaled[['age', 'bathrooms', 'bedrooms', 'sqft', 'price_per_sqft', 'lot_size', 'tax_value']]#features\n",
    "y_train = train.logerror\n",
    "X_validate = validate_scaled[['age', 'bathrooms', 'bedrooms', 'sqft', 'price_per_sqft', 'lot_size', 'tax_value']]#features\n",
    "y_validate = validate.logerror\n",
    "X_test = test_scaled[['age', 'bathrooms', 'bedrooms', 'sqft', 'price_per_sqft', 'lot_size', 'tax_value']]#features\n",
    "y_test = test.logerror\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74b1fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate.rfe(X_train,y_train,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5b9c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate.rfe(X_train,y_train,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1623939",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate.select_kbest(X_train,y_train,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d970c351",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate.select_kbest(X_train,y_train,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74892b91",
   "metadata": {},
   "source": [
    "### Regression Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc0f594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline function calculates baseline and adds columns to the dataframe\n",
    "evaluate.get_baseline(train,train[['sqft']], train['logerror'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0331866",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate.get_residuals(train, train['logerror'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8121eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate.plot_residual(train, train[['sqft']], train['logerror'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f575bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate.regression_errors(train, train['logerror'], train.yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb6cbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate.baseline_mean_errors(train, train['logerror'], train.yhat_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abec8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate.better_than_baseline(regression_errors = True, baseline_mean_errors = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb137365",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bf98d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model_baseline(y_train, y_validate, 'logerror')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9639bcce",
   "metadata": {},
   "source": [
    "## LinearRegression (OLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b570928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.linear_regression(y_train, X_train, y_validate, X_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be68893",
   "metadata": {},
   "source": [
    "## LassoLars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79875966",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.lassolars(y_train, X_train, y_validate, X_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d93b97",
   "metadata": {},
   "source": [
    "## TPolynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e7be38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.polynomialregression(y_train, X_train, y_validate, X_validate, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a81fcd",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de636a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.lassolars_test(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af3978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.linear_regression_test(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88f01fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
